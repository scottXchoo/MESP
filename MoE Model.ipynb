{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Seed set to 1\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Using accelerator: cpu ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import lightning_fabric.utilities.data as lf_data\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, LSTM, NHITS\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "\n",
    "# --- 0. 설정 및 경로 정의 ---\n",
    "KS_MODEL_PATH = './output/kshape_model_k6.pkl'\n",
    "TEST_DATA_PATH = './dataset/preprocessed_test_dataset.npy'\n",
    "MODELS_DIR = './models'\n",
    "\n",
    "# 클러스터 번호에 따른 전문가 모델 경로 매핑\n",
    "EXPERT_MODEL_PATHS = {\n",
    "    0: os.path.join(MODELS_DIR, 'N-BEATS/cluster_0_nbeats/NBEATS_0.ckpt'),\n",
    "    1: os.path.join(MODELS_DIR, 'LSTM/cluster_1_lstm/LSTM_0.ckpt'),\n",
    "    2: os.path.join(MODELS_DIR, 'N-HiTS/cluster_2_nhits/NHITS_0.ckpt'),\n",
    "    3: os.path.join(MODELS_DIR, 'N-BEATS/cluster_3_nbeats/NBEATS_0.ckpt'),\n",
    "    4: os.path.join(MODELS_DIR, 'LSTM/cluster_4_lstm/LSTM_0.ckpt'),\n",
    "    5: os.path.join(MODELS_DIR, 'N-HiTS/cluster_5_nhits/NHITS_0.ckpt'),\n",
    "}\n",
    "\n",
    "# 예측에 필요한 상수\n",
    "INPUT_SIZE = 23 * 60  # 입력 기간 (23시간)\n",
    "HORIZON = 1 * 60      # 예측 기간 (1시간)\n",
    "MAX_EPOCHS = 100\n",
    "INTERVAL = 1\n",
    "HIDDEN_SIZE = 16\n",
    "\n",
    "# 1. 모델 인스턴스 미리 생성\n",
    "lstm_model = LSTM(\n",
    "    h=HORIZON,\n",
    "    input_size=INPUT_SIZE,\n",
    "    encoder_hidden_size=HIDDEN_SIZE,\n",
    "    decoder_hidden_size=HIDDEN_SIZE,\n",
    "    max_steps=MAX_EPOCHS\n",
    ")\n",
    "nbeats_model = NBEATS(input_size=INPUT_SIZE, h=HORIZON, max_steps=MAX_EPOCHS)\n",
    "nhits_model = NHITS(input_size=INPUT_SIZE, h=HORIZON, max_steps=MAX_EPOCHS)\n",
    "\n",
    "# 2. 모델 딕셔너리로 관리\n",
    "expert_models = {\n",
    "    'LSTM': lstm_model,\n",
    "    'NBEATS': nbeats_model,\n",
    "    'NHITS': nhits_model\n",
    "}\n",
    "\n",
    "# 3. cluster_label에 따라 모델 선택\n",
    "cluster_to_model_type = {\n",
    "    0: 'NBEATS',\n",
    "    1: 'LSTM',\n",
    "    2: 'NHITS',\n",
    "    3: 'NBEATS',\n",
    "    4: 'LSTM',\n",
    "    5: 'NHITS'\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"--- Using accelerator: {device} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. K-Shape 모델로 클러스터 예측 (Gating Network) ---\n",
    "def k_shape_predict(dataset):\n",
    "    \"\"\"K-Shape 모델을 로드하여 데이터셋의 클러스터를 예측합니다.\"\"\"\n",
    "    with open(KS_MODEL_PATH, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    cluster_labels = model.predict(dataset)\n",
    "    print(f\"클러스터 예측 완료. 클러스터 분포: {pd.Series(cluster_labels).value_counts().to_dict()}\")\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 전문가 모델 로드 및 예측 ---\n",
    "# 전문가 모델을 효율적으로 관리하기 위해 캐싱(메모리에 저장)합니다.\n",
    "\n",
    "def preprocess_for_nf(sample_input):\n",
    "    input_size = INPUT_SIZE\n",
    "    base_date='2025-01-01'\n",
    "    arr = np.asarray(sample_input).squeeze()\n",
    "    print(f\"arr: {arr}\")\n",
    "    data_range = pd.date_range(base_date, periods=input_size, freq='min')\n",
    "    df = pd.DataFrame({\n",
    "        'unique_id': 'sample',\n",
    "        'ds': data_range,\n",
    "        'y': arr\n",
    "    })\n",
    "    return df\n",
    "\n",
    "loaded_experts = {}\n",
    "\n",
    "def predict_with_expert(cluster_label, input_data):\n",
    "    \"선택된 전문가 모델로 예측을 수행합니다.\"\n",
    "    # 1. 캐시에서 모델 가져오기\n",
    "    if cluster_label in loaded_experts:\n",
    "        model = loaded_experts[cluster_label]\n",
    "        print(f\"loaded_experts[cluster_label]: {loaded_experts[cluster_label]}\")\n",
    "    else:\n",
    "        model_path = EXPERT_MODEL_PATHS.get(cluster_label)\n",
    "        torch.serialization.add_safe_globals([lf_data.AttributeDict, MAE])\n",
    "        checkpoint = torch.load(model_path, weights_only=True)\n",
    "        hyper_params = checkpoint['hyper_parameters']\n",
    "        state_dict = checkpoint['state_dict']\n",
    "\n",
    "        if cluster_label in [0, 3]: # N-BEATS\n",
    "            model = NBEATS(**hyper_params)\n",
    "        elif cluster_label in [1, 4]: # LSTM\n",
    "            model = LSTM(**hyper_params)\n",
    "        elif cluster_label in [2, 5]: # N-HiTS\n",
    "            model = NHITS(**hyper_params)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown cluster label: {cluster_label}\")\n",
    "        \n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        loaded_experts[cluster_label] = model\n",
    "        print(f\"{cluster_label} 번 전문가 모델 {model} 로드 및 캐시 완료\")\n",
    "    \n",
    "    # 2. 예측\n",
    "    df_test = preprocess_for_nf(input_data)\n",
    "    nf = NeuralForecast(models=[model], freq='min')\n",
    "    ## 초기값 설정\n",
    "    nf.id_col = 'unique_id'\n",
    "    nf.time_col = 'ds'\n",
    "    nf.target_col = 'y'\n",
    "    nf.scalers_ = None\n",
    "    ## 학습은 생략\n",
    "    nf._fitted = True\n",
    "\n",
    "    prediction = nf.predict(df=df_test)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 메인 MoE 추론 및 평가 파이프라인 ---\n",
    "X_test_full = np.load(TEST_DATA_PATH)  # 전체 테스트 데이터 로드\n",
    "\n",
    "# 빠른 테스트를 위해 일부만 사용\n",
    "X_test_full = X_test_full\n",
    "\n",
    "# 입력 데이터(처음 23시간)와 실제 정답(마지막 1시간) 분리\n",
    "X_test_input = X_test_full[:, :INPUT_SIZE, :]\n",
    "y_test_true = X_test_full[:, INPUT_SIZE:, :]\n",
    "\n",
    "# --- MoE 추론 시작 ---\n",
    "start_time = time.time()\n",
    "\n",
    "# 1. Gating: 모든 테스트 데이터에 대해 클러스터를 미리 예측\n",
    "all_cluster_labels = k_shape_predict(X_test_full) # all_cluaster_labels을 구할 때는 전체 데이터 사용\n",
    "print(f\"   -> 예측된 클러스터 분포: {np.unique(all_cluster_labels, return_counts=True)}\")\n",
    "\n",
    "# 2. Routing & Prediction: 각 데이터 샘플에 대해 전문가 모델로 예측 수행\n",
    "all_predictions = []\n",
    "for i in range(len(X_test_input)):\n",
    "    sample_input = X_test_input[i]\n",
    "    cluster_label = all_cluster_labels[i]\n",
    "\n",
    "    # 해당 전문가로 예측\n",
    "    prediction = predict_with_expert(cluster_label, sample_input)\n",
    "    all_predictions.append(prediction)\n",
    "    if (i+1) % 10 == 0 or i == len(X_test_input)-1:\n",
    "        print(f\"  [{i+1}/{len(X_test_input)}] 샘플 예측 완료\")\n",
    "\n",
    "# Numpy 배열로 변환\n",
    "y_pred_moe = np.array(all_predictions)\n",
    "\n",
    "end_time = time.time()\n",
    "inference_time = end_time - start_time\n",
    "print(f\"MoE 모델 예측 결과: {y_pred_moe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true shape: (3, 60), y_pred shape: (3, 60)\n",
      "MoE 모델 MAE: 0.3426\n",
      "MoE 모델 RMSE: 0.4355\n",
      "MoE 모델 MAPE: 75.6388%\n",
      "MoE 모델 추론 시간: 1.33초\n",
      "샘플 당 평균 추론 시간: 443.0676 ms\n"
     ]
    }
   ],
   "source": [
    "# --- 4. 평가 지표 계산 ---\n",
    "y_true_final = y_test_true.squeeze(-1)\n",
    "y_pred_final = np.array([\n",
    "    [row[-1] for row in sample] for sample in y_pred_moe\n",
    "])\n",
    "y_pred = np.array([[row[-1] for row in y_pred_moe]]) # y_pred: (샘플 수, HORIZON, 3) => 예측값만 추출\n",
    "print(f\"y_true shape: {y_true_final.shape}, y_pred shape: {y_pred_final.shape}\")\n",
    "\n",
    "# MAE 계산\n",
    "mae_per_sample = np.mean(np.abs(y_true_final - y_pred_final), axis=1)\n",
    "mae = np.mean(mae_per_sample)\n",
    "print(f\"MoE 모델 MAE: {mae:.4f}\")\n",
    "\n",
    "# RMAE\n",
    "rmse_per_sample = np.sqrt(np.mean((y_true_final - y_pred_final) ** 2, axis=1))\n",
    "rmse = np.mean(rmse_per_sample)\n",
    "print(f\"MoE 모델 RMSE: {rmse:.4f}\")\n",
    "\n",
    "# MAPE\n",
    "mape_list = []\n",
    "for yt, yp in zip(y_true_final, y_pred_final):\n",
    "    mask = np.abs(yt) > 1e-1\n",
    "    if np.any(mask):\n",
    "        mape = np.mean(np.abs((yt[mask] - yp[mask]) / (yt[mask] + 1e-8))) * 100\n",
    "        mape_list.append(mape)\n",
    "    else:\n",
    "        mape_list.append(np.nan)  # 실제값이 모두 0이면 NaN\n",
    "\n",
    "mape = np.nanmean(mape_list)\n",
    "print(f\"MoE 모델 MAPE: {mape:.4f}%\")\n",
    "\n",
    "print(f\"MoE 모델 추론 시간: {inference_time:.2f}초\")\n",
    "print(f\"샘플 당 평균 추론 시간: {(inference_time / len(X_test_input))*1000:.4f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
